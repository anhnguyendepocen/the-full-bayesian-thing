---
title: "ch6"
author: "mht"
date: "October 21, 2014"
output: html_document
---

# Chapter 6: Latent Mixture Models

Suppose a group of 15 people sit an exam made up of 40 true-or-false questions, and they get 21, 17, 21, 18, 22, 31, 31, 34, 34, 35, 35, 36, 39, 36, and 35 right. These scores suggest that the first 5 people were just guessing, but the last 10 had some level of knowledge.

One way to make statistical inferences along these lines is to assume there are two different groups of people. These groups have different probabilities of success, with the guessing group having a probability of 0.5, and the knowledge group having a probability greater than 0.5. Whether each person belongs to the first or the second group is a latent or unobserved variable that can take just two values. Using this approach, the goal is to infer to which group each person belongs, and also the rate of success for the knowledge group.

This type of model is known as a latent-mixture model, because the data are assumed to be generated by two different processes that combine or mix, and im- portant properties of that mixture are unobserved or latent. In this case, the two components that mix are the guessing and knowledge processes, and the group membership of each person is latent.



```{r 6.1.1,fig.width=10, fig.height=4}
library(R2jags)
library(gridExtra)
library(reshape2)

setwd("/Users/mht/Documents/learning/tfbt/Lee&Wagenmakers/Code/ParameterEstimation/DataAnalysis")


cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dbeta(1,1)I(0.5,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:	
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
   			 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')

b<-ggplot(melt(df[,2:length(df)]),aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.1 success rate and group membership')
grid.arrange(a,b,nrow=1, main='6.1.1 success rate and group membership')
```

### Ex 6.1.1

Draw some conclusions about the problem from the posterior distribution. Who belongs to what group, and how confident are you?

### Ex 6.1.2

The initial allocations of people to the two groups in this code is random, and so will be different every time you run it. Check that this does not affect the final results from sampling.

### Ex 6.1.3 

Include an extra person in the exam, with a score of 28 out of 40. What does their posterior for z tell you? Now add four extra people, all with the score 28 out of 40. Explain the change these extra people make to the inference


```{r 6.1.3a,fig.width=10, fig.height=4, echo=FALSE}
k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
   			 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')

b<-ggplot(melt(df[,2:length(df)]),aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.3a success rate and group+1 membership')
grid.arrange(a,b,nrow=1, main='6.1.3a success rate and group+1 membership')

```

Now add four extra people, all with the score 28 out of 40. Explain the change these extra people make to the inference.

```{r 6.1.3b,fig.width=10, fig.height=4, echo=FALSE}
k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
     		 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')

b<-ggplot(melt(df[,2:length(df)]),aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.3b success rate and group+5 membership')
grid.arrange(a,b,nrow=1, main='6.1.3b success rate and group+5 membership')

```


### Ex. 6.1.4 

What happens if you change the prior on the success rate of the second group to be uniform over the whole range from 0 to 1, and so allow for worse-than-guessing performance?


```{r 6.1.4,fig.width=10, fig.height=4, echo=FALSE}
cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dunif(0,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")


samples <- jags(data, inits=myinits, parameters,
       	 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')

b<-ggplot(melt(df[,2:length(df)]),aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.4 success rate and group+5 membership, uniform(0,1) prior')
grid.arrange(a,b,nrow=1, main='6.1.4 success rate and group+5 membership, uniform(0,1) prior')

```

### Ex. 6.1.5 

What happens if you change the initial expectation that everybody is equally likely to belong to either group, and have an expectation that people generally are not guessing, with (say), z_i ~ Bernoulli(0.9)?


```{r 6.1.5,fig.width=10, fig.height=4, echo=FALSE}
cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.9)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dunif(0,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})


k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
          model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')

b<-ggplot(melt(df[,2:length(df)]),aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.5 success rate and group+5 membership, uniform(0,1) prior \n z_i~Bernoulli(0.9)')
grid.arrange(a,b,nrow=1, main='6.1.5 success rate and group+5 membership, uniform(0,1) prior \n z_i~Bernoulli(0.9)')

```

# 6.2 Exam scores with individual differences 

The previous example shows how sampling can model data as coming from a mixture of sources, and infer properties of these latent groups. But the specific model has at least one big weakness, which is that it assumes all the people in the knowledge group have exactly the same rate of success on the questions.

One straightforward way to allow for individual differences in the knowledge group is to extend the model hierarchically. One convenient (but not perfect) choice for this “individual differences” distribution is a Gaussian. It has the problem of allowing for success rates below zero and above one. An inelegant but practical and effective way to deal with this is simply to restrict the sampled success rates to the valid range.

```{r 6.2.1 ,fig.width=10, fig.height=4}
cat('# Exam Scores With Individual Differences
model{
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi[i]
    k[i] ~ dbin(theta[i],n)
  }
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # The Second Group Allows Individual Differences
  for (i in 1:p){
    # Second Group Drawn From A Censored Gaussian Distribution
    phi[i] ~ dnorm(mu,lambda)T(0,1)
  }   
  # First Group Guesses
  psi <- 0.5
  # Second Group Mean, Precision (And Standard Deviation)
  mu ~ dbeta(1,1)T(.5,1) # >0.5 Average Success Rate
  lambda ~ dgamma(.001,.001)
  sigma <- 1/sqrt(lambda) 
  # Posterior Predictive For Second Group
  predphi ~ dnorm(mu,lambda)T(0,1)
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35)
p <- length(k) #number of people
n <- 40 # number of questions

data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(mu = 0.75, lambda = 1, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:	
parameters <- c("predphi","theta","z","mu","sigma")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
	 			 model.file =f, n.chains=1, n.iter=2000, 
         n.burnin=1000, n.thin=1, DIC=T)


df<-data.frame(predphi = samples$BUGSoutput$sims.list$predphi,
               theta = samples$BUGSoutput$sims.list$theta,
               z = samples$BUGSoutput$sims.list$z,
                 mu = samples$BUGSoutput$sims.list$mu,
                 sigma = samples$BUGSoutput$sims.list$sigma)

a<-qplot(data=melt(df$mu),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('mu')

b<-ggplot(melt(df[,c('z.1','z.2','z.3','z.4','z.5',
                     'z.6','z.7','z.8','z.9','z.10',
                     'z.11','z.12','z.13','z.14','z.15')])
          ,aes(x=value,fill=value))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.2.1 success rate and group membership w/ individual differences')
grid.arrange(a,b,nrow=1, main='6.2.1 success rate and group membership w/ individual differences')
```

### Exercise 6.2.1 

Compare the results of the hierarchical model with the original model that did not allow for individual differences.

### Exercise 6.2.2 

Interpret the posterior distribution of the variable predphi. How does this distribution relate to the posterior distribution for mu?

```{r 6.2.2,fig.width=10, fig.height=4}
quartz('6.2.2 posterior of predphi')
qplot(data=melt(df$predphi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('posterior predictive phi')
```

### Exercise 6.2.3 

In what sense could the latent assignment of people to groups in this case study be considered a form of model selection?

# 6.3 Twenty Questions

Suppose a group of 10 people attend a lecture, and are asked a set of 20 questions afterwards, with every answer being either correct or incorrect. We want to infer two things: (1) how well each person attended to the lecture, (2) how hard each of the questions was.

One way to make these inferences is to specify a model of how a person’s attentiveness and a question’s difficulty combine to give an overall probability that the question will be answered correctly. A very simple model involves assuming that each person listens to some proportion of the lecture, and that each question has some probability of being answered correctly if the person was listening at the right point in the lecture.


```{r 6.3.1 ,fig.width=10, fig.height=8}
cat('# Twenty Questions
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
      k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- p[i]*q[j]
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,0,0,
      0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
      0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
      1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
      1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
      0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
      1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
parameters <- c("p", "q")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
  	 			 model.file =f, n.chains=1, n.iter=10000, 
           n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('person ability')+ guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('question difficulty')+ guides(fill=FALSE)

#quartz('6.3.1 marginal distributions of person ability and question difficulty')
grid.arrange(a,b,nrow=2, main='6.3.1 marginal distributions of person ability and question difficulty')
```

### Ex 6.3.1

Draw some conclusions about how well the various people listened, and about the difficulties of the various questions. Do the marginal posterior distributions you are basing your inference on seem intuitively reasonable?

### Ex 6.3.2 Missing data
```{r 6.3.2 ,fig.width=10, fig.height=8}
cat('# Twenty Questions
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
      k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- p[i]*q[j]
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
  NA.array[1] <- k[1,13]
  NA.array[2] <- k[8,5]
  NA.array[3] <- k[10,18]
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,NA,0,0,1,0,1,0,0,
        0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
        0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
        1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
        1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
        0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
        0,0,0,0,NA,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
        1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,NA,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
  parameters <- c("p", "q", "NA.array")

  # The following command calls JAGS with specific options.
  # For a detailed description the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
    	 			 model.file =f, n.chains=1, n.iter=10000, 
             n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q,
               na.array = samples$BUGSoutput$sims.list$NA.array)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('person ability')+ guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('question difficulty')+ guides(fill=FALSE)

c<-qplot(data=melt(df[,substr(names(df),1,2)=='na']),
    x=value,fill=variable,geom='histogram',binwidth=0.3)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('NA values')+ guides(fill=FALSE)



#quartz(main='6.3.2 marginal distributions of person ability, question difficulty, NA values')

grid.arrange(a,b,c,nrow=3, main='6.3.2 marginal distributions of person ability, question difficulty, NA values')
```

### 6.3.3 Rasch model

```{r 6.3.1 ,fig.width=10, fig.height=8}
cat('# Twenty Questions Using Rasch Model
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
       k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- exp(p[i]-q[j])/(1+exp(p[i]-q[j]))
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,0,0,
      0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
      0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
      1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
      1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
      0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
      1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
parameters <- c("p", "q")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
     			 model.file =f, n.chains=1, n.iter=10000, 
           n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('person ability')+ guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('question difficulty')+ guides(fill=FALSE)

#quartz('6.3.3 Rasch model of person ability and question difficulty')
grid.arrange(a,b,nrow=2, main='6.3.3 Rasch model of person ability and question difficulty')
```
