---
title: "ch6"
author: "mht"
date: "October 21, 2014"
output: html_document
---

# Chapter 6: Latent Mixture Models

Suppose a group of 15 people sit an exam made up of 40 true-or-false questions, and they get 21, 17, 21, 18, 22, 31, 31, 34, 34, 35, 35, 36, 39, 36, and 35 right. These scores suggest that the first 5 people were just guessing, but the last 10 had some level of knowledge.

One way to make statistical inferences along these lines is to assume there are two different groups of people. These groups have different probabilities of success, with the guessing group having a probability of 0.5, and the knowledge group having a probability greater than 0.5. Whether each person belongs to the first or the second group is a latent or unobserved variable that can take just two values. Using this approach, the goal is to infer to which group each person belongs, and also the rate of success for the knowledge group.

This type of model is known as a latent-mixture model, because the data are assumed to be generated by two different processes that combine or mix, and im- portant properties of that mixture are unobserved or latent. In this case, the two components that mix are the guessing and knowledge processes, and the group membership of each person is latent.



```{r 6.1.1,fig.width=10, fig.height=4}
library(R2jags)
library(gridExtra)
library(reshape2)

setwd("/Users/mht/Documents/learning/tfbt/Lee&Wagenmakers/Code/ParameterEstimation/LatentMixtures")


cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dbeta(1,1)I(0.5,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:	
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
   			 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')+
  xlim(0,1)

b<-ggplot(melt(df[,2:length(df)]),aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.1 success rate and group membership')
grid.arrange(a,b,nrow=1, main='6.1.1 success rate and group membership')
```

### Ex 6.1.1

Draw some conclusions about the problem from the posterior distribution. Who belongs to what group, and how confident are you?

### Ex 6.1.2

The initial allocations of people to the two groups in this code is random, and so will be different every time you run it. Check that this does not affect the final results from sampling.

### Ex 6.1.3 

Include an extra person in the exam, with a score of 28 out of 40. What does their posterior for z tell you? Now add four extra people, all with the score 28 out of 40. Explain the change these extra people make to the inference


```{r 6.1.3a,fig.width=10, fig.height=4, echo=FALSE}
k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
   			 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')+
  xlim(0,1)

b<-ggplot(melt(df[,2:length(df)]),aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.3a success rate and group+1 membership')
grid.arrange(a,b,nrow=1, main='6.1.3a success rate and group+1 membership')

```

Now add four extra people, all with the score 28 out of 40. Explain the change these extra people make to the inference.

```{r 6.1.3b,fig.width=10, fig.height=4, echo=FALSE}
k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
     		 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')+
  xlim(0,1)

b<-ggplot(melt(df[,2:length(df)]),aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.3b success rate and group+5 membership')
grid.arrange(a,b,nrow=1, main='6.1.3b success rate and group+5 membership')

```


### Ex. 6.1.4 

What happens if you change the prior on the success rate of the second group to be uniform over the whole range from 0 to 1, and so allow for worse-than-guessing performance?


```{r 6.1.4,fig.width=10, fig.height=4, echo=FALSE}
cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dunif(0,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")


samples <- jags(data, inits=myinits, parameters,
       	 model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')+
  xlim(0,1)

b<-ggplot(melt(df[,2:length(df)]),aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.4 success rate and group+5 membership, uniform(0,1) prior')
grid.arrange(a,b,nrow=1, main='6.1.4 success rate and group+5 membership, uniform(0,1) prior')

```

### Ex. 6.1.5 

What happens if you change the initial expectation that everybody is equally likely to belong to either group, and have an expectation that people generally are not guessing, with (say), z_i ~ Bernoulli(0.9)?


```{r 6.1.5,fig.width=10, fig.height=4, echo=FALSE}
cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.9)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dunif(0,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n)
  }
}', file={f<-tempfile()})


k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions


data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(phi = 0.75, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("phi","z")

samples <- jags(data, inits=myinits, parameters,
          model.file =f, n.chains=1, n.iter=1000, 
         n.burnin=1, n.thin=1, DIC=T)

df<-data.frame(phi = samples$BUGSoutput$sims.list$phi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('phi')+
  xlim(0,1)

b<-ggplot(melt(df[,2:length(df)]),aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.1.5 success rate and group+5 membership, uniform(0,1) prior \n z_i~Bernoulli(0.9)')
grid.arrange(a,b,nrow=1, main='6.1.5 success rate and group+5 membership, uniform(0,1) prior \n z_i~Bernoulli(0.9)')

```

# 6.2 Exam scores with individual differences 

The previous example shows how sampling can model data as coming from a mixture of sources, and infer properties of these latent groups. But the specific model has at least one big weakness, which is that it assumes all the people in the knowledge group have exactly the same rate of success on the questions.

One straightforward way to allow for individual differences in the knowledge group is to extend the model hierarchically. One convenient (but not perfect) choice for this “individual differences” distribution is a Gaussian. It has the problem of allowing for success rates below zero and above one. An inelegant but practical and effective way to deal with this is simply to restrict the sampled success rates to the valid range.

```{r 6.2.1 ,fig.width=10, fig.height=4}
cat('# Exam Scores With Individual Differences
model{
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi[i]
    k[i] ~ dbin(theta[i],n)
  }
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # The Second Group Allows Individual Differences
  for (i in 1:p){
    # Second Group Drawn From A Censored Gaussian Distribution
    phi[i] ~ dnorm(mu,lambda)T(0,1)
  }   
  # First Group Guesses
  psi <- 0.5
  # Second Group Mean, Precision (And Standard Deviation)
  mu ~ dbeta(1,1)T(.5,1) # >0.5 Average Success Rate
  lambda ~ dgamma(.001,.001)
  sigma <- 1/sqrt(lambda) 
  # Posterior Predictive For Second Group
  predphi ~ dnorm(mu,lambda)T(0,1)
}', file={f<-tempfile()})

k <- c(21,17,21,18,22,31,31,34,34,35,35,36,39,36,35,28,28,28,28,28)
p <- length(k) #number of people
n <- 40 # number of questions

data <- list("p", "k", "n") # to be passed on to JAGS
myinits <-  list(
  list(mu = 0.75, lambda = 1, z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:	
parameters <- c("predphi","theta","z","mu","sigma")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
	 			 model.file =f, n.chains=1, n.iter=2000, 
         n.burnin=1000, n.thin=1, DIC=T)


df<-data.frame(predphi = samples$BUGSoutput$sims.list$predphi,
               theta = samples$BUGSoutput$sims.list$theta,
               z = samples$BUGSoutput$sims.list$z,
                 mu = samples$BUGSoutput$sims.list$mu,
                 sigma = samples$BUGSoutput$sims.list$sigma)

a<-qplot(data=melt(df$mu),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('mu')+
  xlim(0,1)

b<-ggplot(melt(df[,c('z.1','z.2','z.3','z.4','z.5',
                     'z.6','z.7','z.8','z.9','z.10',
                     'z.11','z.12','z.13','z.14','z.15',
                     'z.16','z.17','z.18','z.19','z.20')])
          ,aes(x=factor(value),fill=factor(value)))+
  facet_wrap(~variable,scales='fixed')+
  geom_histogram(binwidth=0.1)+
  theme_bw()+
  xlab('z (group membership)')

#quartz('6.2.1 success rate and group membership w/ individual differences')
grid.arrange(a,b,nrow=1, main='6.2.1 success rate and group membership w/ individual differences')
```

### Exercise 6.2.1 

Compare the results of the hierarchical model with the original model that did not allow for individual differences.

### Exercise 6.2.2 

Interpret the posterior distribution of the variable predphi. How does this distribution relate to the posterior distribution for mu?

```{r 6.2.2,fig.width=10, fig.height=4}
quartz('6.2.2 posterior of predphi')
qplot(data=melt(df$predphi),x=value,geom='histogram',binwidth=0.008)+
  theme_bw()+
  xlab('posterior predictive phi')+
  xlim(0,1)
```

### Exercise 6.2.3 

In what sense could the latent assignment of people to groups in this case study be considered a form of model selection?

# 6.3 Twenty Questions

Suppose a group of 10 people attend a lecture, and are asked a set of 20 questions afterwards, with every answer being either correct or incorrect. We want to infer two things: (1) how well each person attended to the lecture, (2) how hard each of the questions was.

One way to make these inferences is to specify a model of how a person’s attentiveness and a question’s difficulty combine to give an overall probability that the question will be answered correctly. A very simple model involves assuming that each person listens to some proportion of the lecture, and that each question has some probability of being answered correctly if the person was listening at the right point in the lecture.


```{r 6.3.1 ,fig.width=10, fig.height=8}
cat('# Twenty Questions
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
      k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- p[i]*q[j]
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,0,0,
      0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
      0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
      1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
      1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
      0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
      1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
parameters <- c("p", "q")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
  	 			 model.file =f, n.chains=1, n.iter=10000, 
           n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person ability')+ 
  xlim(0,1)+
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question difficulty')+ 
  xlim(0,1)+
  guides(fill=FALSE)

#quartz('6.3.1 marginal distributions of person ability and question difficulty')
grid.arrange(a,b,nrow=2, main='6.3.1 marginal distributions of person ability and question difficulty')
```

### Ex 6.3.1

Draw some conclusions about how well the various people listened, and about the difficulties of the various questions. Do the marginal posterior distributions you are basing your inference on seem intuitively reasonable?

### Ex 6.3.2 Missing data
```{r 6.3.2 ,fig.width=10, fig.height=8}
cat('# Twenty Questions
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
      k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- p[i]*q[j]
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
  NA.array[1] <- k[1,13]
  NA.array[2] <- k[8,5]
  NA.array[3] <- k[10,18]
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,NA,0,0,1,0,1,0,0,
        0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
        0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
        1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
        1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
        0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
        0,0,0,0,NA,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
        1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,NA,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
  parameters <- c("p", "q", "NA.array")

  # The following command calls JAGS with specific options.
  # For a detailed description the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
    	 			 model.file =f, n.chains=1, n.iter=10000, 
             n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q,
               na.array = samples$BUGSoutput$sims.list$NA.array)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person ability')+ guides(fill=FALSE)
  xlim(0,1)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question difficulty')+ guides(fill=FALSE)+
  xlim(0,1)

c<-qplot(data=melt(df[,substr(names(df),1,2)=='na']),
    x=value,fill=variable,geom='histogram',binwidth=0.3)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('NA values')+ guides(fill=FALSE)+
  xlim(0,1)



#quartz(main='6.3.2 marginal distributions of person ability, question difficulty, NA values')

grid.arrange(a,b,c,nrow=3, main='6.3.2 marginal distributions of person ability, question difficulty, NA values')
```

### 6.3.3 Rasch model

```{r 6.3.3 ,fig.width=10, fig.height=8}
cat('# Twenty Questions Using Rasch Model
model{
  # Correctness Of Each Answer Is Bernoulli Trial
  for (i in 1:np){
    for (j in 1:nq){
       k[i,j] ~ dbern(theta[i,j])
    }
  }
  # Probability Correct Is Product Of Question By Person Rates
  for (i in 1:np){
    for (j in 1:nq){
      theta[i,j] <- exp(p[i]-q[j])/(1+exp(p[i]-q[j]))
    }
  }
  # Priors For People and Questions
  for (i in 1:np){
    p[i] ~ dbeta(1,1)
  }
  for (j in 1:nq){
    q[j] ~ dbeta(1,1)
  }
}', file={f<-tempfile()})

k <- c(1,1,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,0,0,
      0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,
      0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,
      1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,0,0,1,0,0,
      1,1,0,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,0,
      0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
      0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,1,
      1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0)

k <- matrix(k, nrow=10, byrow=T)

np <- nrow(k)
nq <- ncol(k)

data <- list("np","nq","k") # to be passed on to JAGS
myinits <- list(
  list(q = runif(nq), p = runif(np)))

# parameters to be monitored:  
parameters <- c("p", "q")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
     			 model.file =f, n.chains=1, n.iter=10000, 
           n.burnin=1, n.thin=1, DIC=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.
  
df<-data.frame(p = samples$BUGSoutput$sims.list$p,
               q = samples$BUGSoutput$sims.list$q)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('person ability')+ guides(fill=FALSE)+
  xlim(0,1)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='q']),
    x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable)+
  xlab('question difficulty')+ guides(fill=FALSE)+
  xlim(0,1)

#quartz('6.3.3 Rasch model of person ability and question difficulty')
grid.arrange(a,b,nrow=2, main='6.3.3 Rasch model of person ability and question difficulty')
```


# 6.4 The two-country quiz

Suppose a group of people take a historical quiz, and each answer for each person is scored as correct or incorrect. Some of the people are Thai, and some are Moldovan. Some of the questions are about Thai history, and it is more likely the answer would be known by a Thai person than a Moldovan. The rest of the questions are about Moldovan history, and it is more likely the answer would be known by a Moldovan than a Thai.

We do not know who is Thai or Moldovan, and we do not know the content of the questions.

A good way to make these inferences formally is to assume there are two types of answers. For those where the nationality of the person matches the origin of the question, the answer will be correct with high probability. For those where a person is being asked about the other country, the answer will have a very low probability of being correct.

```{r 6.4.1,fig.width=10, fig.height=8}
cat('# The Two Country Quiz
model{
  # Probability of Answering Correctly
  alpha ~ dunif(0,1)    # Match
  beta ~ dunif(0,alpha) # Mismatch   
  # Group Membership For People and Questions
  for (i in 1:nx){
    x[i] ~ dbern(0.5)
    x1[i] <- x[i]+1
  }
  for (j in 1:nz){
    z[j] ~ dbern(0.5)
    z1[j] <- z[j]+1
  }   
  # Probability Correct For Each Person-Question Combination By Groups
  for (i in 1:nx){
    for (j in 1:nz){
      theta[i,j,1,1] <- alpha
      theta[i,j,1,2] <- beta
      theta[i,j,2,1] <- beta
      theta[i,j,2,2] <- alpha
    }
  }   
  # Data Are Bernoulli By Rate
  for (i in 1:nx){
    for (j in 1:nz){
      k[i,j] ~ dbern(theta[i,j,x1[i],z1[j]])
    }
  }   
}', file={f<-tempfile()})


k <- c(1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      0,1,1,0,0,1,0,0,
      0,1,1,0,0,1,1,0,
      1,0,0,1,1,0,0,1,
      0,0,0,1,1,0,0,1,
      0,1,0,0,0,1,1,0,
      0,1,1,1,0,1,1,0)
k <- matrix(k, nrow=8, byrow=T)

nx <- nrow(k)
nz <- ncol(k)

data <- list("nx","nz","k")
inits <-  list(
  list(z = round(runif(nz)), x = round(runif(nx)), alpha=0.5, beta=0.5))

parameters <- c("z", "x", "alpha", "beta")

samples <- jags(data, inits, parameters,
  	 			 model.file =f, n.chains=1, n.iter=2000, 
           n.burnin=1000, n.thin=1, DIC=T)
 
df<-data.frame(alpha = samples$BUGSoutput$sims.list$alpha,
               beta = samples$BUGSoutput$sims.list$beta,
               x = samples$BUGSoutput$sims.list$x,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='x']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person country of origin')+ 
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='z']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question country of origin')+ 
  guides(fill=FALSE)

c<-qplot(data=melt(df$alpha),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('alpha')+
  xlim(0,1)

d<-qplot(data=melt(df$beta),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('beta')+
  xlim(0,1)


grid.arrange(a,b,c,d,nrow=2)
```


### Exercise 6.4.1 

Interpret the posterior distributions for x[i], z[j], alpha, and beta. Do the formal inferences agree with your original intuitions?

### Exercise 6.4.2 

The priors on the probabilities of answering correctly capture knowledge about what it means to match and mismatch, by imposing an order constraint α ≥ β. Change the code so that this information is not included, by using priors alpha∼dbeta(1,1) and beta∼dbeta(1,1). Run a few chains against the same data, until you get an inappropriate, and perhaps counter-intuitive, result. The problem that is being encountered is known as model indeterminacy or label-switching. Describe the problem, and discuss why it comes about.

```{r 6.4.2,fig.width=10, fig.height=8}
cat('# The Two Country Quiz
model{
  # Probability of Answering Correctly
  alpha ~ dbeta(1,1)    # Match
  beta ~ dbeta(1,1) # Mismatch   
  # Group Membership For People and Questions
  for (i in 1:nx){
    x[i] ~ dbern(0.5)
    x1[i] <- x[i]+1
  }
  for (j in 1:nz){
    z[j] ~ dbern(0.5)
    z1[j] <- z[j]+1
  }   
  # Probability Correct For Each Person-Question Combination By Groups
  for (i in 1:nx){
    for (j in 1:nz){
      theta[i,j,1,1] <- alpha
      theta[i,j,1,2] <- beta
      theta[i,j,2,1] <- beta
      theta[i,j,2,2] <- alpha
    }
  }   
  # Data Are Bernoulli By Rate
  for (i in 1:nx){
    for (j in 1:nz){
      k[i,j] ~ dbern(theta[i,j,x1[i],z1[j]])
    }
  }   
}', file={f<-tempfile()})


k <- c(1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      0,1,1,0,0,1,0,0,
      0,1,1,0,0,1,1,0,
      1,0,0,1,1,0,0,1,
      0,0,0,1,1,0,0,1,
      0,1,0,0,0,1,1,0,
      0,1,1,1,0,1,1,0)
k <- matrix(k, nrow=8, byrow=T)

nx <- nrow(k)
nz <- ncol(k)

data <- list("nx","nz","k")
inits <-  list(
  list(z = round(runif(nz)), x = round(runif(nx)), alpha=0.5, beta=0.5))

parameters <- c("z", "x", "alpha", "beta")

samples <- jags(data, inits, parameters,
     			 model.file =f, n.chains=1, n.iter=2000, 
           n.burnin=1000, n.thin=1, DIC=T)
 
df<-data.frame(alpha = samples$BUGSoutput$sims.list$alpha,
               beta = samples$BUGSoutput$sims.list$beta,
               x = samples$BUGSoutput$sims.list$x,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='x']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person country of origin')+ 
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='z']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question country of origin')+ 
  guides(fill=FALSE)

c<-qplot(data=melt(df$alpha),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('alpha')+
  xlim(0,1)

d<-qplot(data=melt(df$beta),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('beta')+
  xlim(0,1)


grid.arrange(a,b,c,d,nrow=2)
```

The problem is that the alpha (the probability of answering correctly for a question about your home country) becomes (in some chains) lower than beta (the probability of answering correctly for a question about a home country different from your own). This is because in this model formulation, alpha and beta are interchangable. 

#### Exercise 6.4.3 

Now suppose that three extra people enter the room late, and begin to take the quiz. One of them (Late Person 1) has answered the first four questions, the next (Late Person 2) has only answered the first question, and the final new person (Late Person 3) is still sharpening their pencil, and has not started the quiz. This situation can be represented as an updated data set, now with missing data. Interpret the inferences the model makes about the nationality of the late people, and whether or not they will get the unfinished questions correct.

```{r 6.4.3,fig.width=10, fig.height=16}
cat('# The Two Country Quiz
model{
  # Probability of Answering Correctly
  alpha ~ dunif(0,1)    # Match
  beta ~ dunif(0,alpha) # Mismatch    
  # Group Membership For People and Questions
  for (i in 1:nx){
    x[i] ~ dbern(0.5)
    x1[i] <- x[i]+1
  }
  for (j in 1:nz){
    z[j] ~ dbern(0.5)
    z1[j] <- z[j]+1
  }   
  # Probability Correct For Each Person-Question Comination By Groups
  for (i in 1:nx){
    for (j in 1:nz){
      theta[i,j,1,1] <- alpha
      theta[i,j,1,2] <- beta
      theta[i,j,2,1] <- beta
      theta[i,j,2,2] <- alpha
    }
  }   
  # Data Are Bernoulli By Rate
  for (i in 1:nx){
    for (j in 1:nz){
      k[i,j] ~ dbern(theta[i,j,x1[i],z1[j]])
    }
  } 
# Take care of NAs:
  for (j in 5:8)
  { 
    NA.LP1[j-4] <- k[9,j]
  }
  for (j in 2:8)
  { 
    NA.LP2[j-1] <- k[10,j]
  }
  for (j in 1:8)
  { 
    NA.LP3[j]   <- k[11,j]
  }   
}', file={f<-tempfile()})

k <- c(1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      0,1,1,0,0,1,0,0,
      0,1,1,0,0,1,1,0,
      1,0,0,1,1,0,0,1,
      0,0,0,1,1,0,0,1,
      0,1,0,0,0,1,1,0,
      0,1,1,1,0,1,1,0,
      1,0,0,1,NA,NA,NA,NA,
      0,NA,NA,NA,NA,NA,NA,NA,
      NA,NA,NA,NA,NA,NA,NA,NA)
k <- matrix(k, nrow=11, byrow=T)

nx <- nrow(k)
nz <- ncol(k)

data <- list("nx","nz","k")
inits <-  list(
  list(z = round(runif(nz)), x = round(runif(nx)), alpha=0.5, beta=0.5))

  parameters <- c("z", "x", "alpha", "beta", "NA.LP1", "NA.LP2", "NA.LP3")

  # The following command calls JAGS with specific options.
  # For a detailed description the R2jags documentation.
  samples <- jags(data, inits, parameters,
       			 model.file =f, n.chains=1, 
             n.iter=2000, n.burnin=1000, n.thin=1, DIC=T)
 
df<-data.frame(alpha = samples$BUGSoutput$sims.list$alpha,
               beta = samples$BUGSoutput$sims.list$beta,
               x = samples$BUGSoutput$sims.list$x,
               z = samples$BUGSoutput$sims.list$z,
               na.lp1 = samples$BUGSoutput$sims.list$NA.LP1,
               na.lp2 = samples$BUGSoutput$sims.list$NA.LP2,
               na.lp3 = samples$BUGSoutput$sims.list$NA.LP3)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='x']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person country of origin')+ 
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='z']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question country of origin')+ 
  guides(fill=FALSE)

c<-qplot(data=melt(df$alpha),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('alpha')+
  xlim(0,1)

d<-qplot(data=melt(df$beta),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('beta')+
  xlim(0,1)

e<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp1']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 1')+ 
  guides(fill=FALSE)

f<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp2']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 2')+ 
  guides(fill=FALSE)

g<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp3']),
  x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 3')+ 
  guides(fill=FALSE)

#quartz('6.4.3')
grid.arrange(a,b,c,d,e,f,g,nrow=4)
```



### Exercise 6.4.4 

Finally, suppose that you are now given the correctness scores for a set of 10 new people, whose data were not previously available, but who form part of the same group of people we are studying. Interpret the inferences the model makes about the nationality of the new people. Revisit the inferences about the late people, and whether or not they will get the unfinished questions correct. Does the inference drawn by the model for the third late person match your intuition? There is a problem here. How could it be fixed?

```{r 6.4.4,fig.width=10, fig.height=16}
cat('# The Two Country Quiz
model{
  # Probability of Answering Correctly
  alpha ~ dunif(0,1)     # Match
  beta ~ dunif(0,alpha) # Mismatch    
  # Group Membership For People and Questions
  for (i in 1:nx){
    x[i] ~ dbern(0.5)
    x1[i] <- x[i]+1
  }
  for (j in 1:nz){
    z[j] ~ dbern(0.5)
    z1[j] <- z[j]+1
  }   
  # Probability Correct For Each Person-Question Comination By Groups
  for (i in 1:nx){
    for (j in 1:nz){
      theta[i,j,1,1] <- alpha
      theta[i,j,1,2] <- beta
      theta[i,j,2,1] <- beta
      theta[i,j,2,2] <- alpha
    }
  }   
  # Data Are Bernoulli By Rate
  for (i in 1:nx){
    for (j in 1:nz){
      k[i,j] ~ dbern(theta[i,j,x1[i],z1[j]])
    }
  } 
# Take care of NAs:
  for (j in 5:8)
  {  
    NA.LP1[j-4] <- k[19,j]
  }
  for (j in 2:8)
  { 
    NA.LP2[j-1] <- k[20,j]
  }
  for (j in 1:8)
  { 
    NA.LP3[j]   <- k[21,j]
  } 
}', file={f<-tempfile()})

k <- c(1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      1,0,0,1,1,0,0,1,
      0,1,1,0,0,1,0,0,
      0,1,1,0,0,1,1,0,
      1,0,0,1,1,0,0,1,
      0,0,0,1,1,0,0,1,
      0,1,0,0,0,1,1,0,
      0,1,1,1,0,1,1,0,
      1,0,0,1,NA,NA,NA,NA,
      0,NA,NA,NA,NA,NA,NA,NA,
      NA,NA,NA,NA,NA,NA,NA,NA)
k <- matrix(k, nrow=21, byrow=T)

nx <- nrow(k)
nz <- ncol(k)

data <- list("nx","nz","k")
inits <-  list(
  list(z = round(runif(nz)), x = round(runif(nx)), alpha=0.5, beta=0.5))

parameters <- c("z", "x", "alpha", "beta", "NA.LP1", "NA.LP2", "NA.LP3")

# The following command calls JAGS with specific options.
# For a detailed description the R2jags documentation.
samples <- jags(data, inits, parameters,
     			 model.file =f, n.chains=1, 
           n.iter=2000, n.burnin=1000, n.thin=1, DIC=T)
 
df<-data.frame(alpha = samples$BUGSoutput$sims.list$alpha,
               beta = samples$BUGSoutput$sims.list$beta,
               x = samples$BUGSoutput$sims.list$x,
               z = samples$BUGSoutput$sims.list$z,
               na.lp1 = samples$BUGSoutput$sims.list$NA.LP1,
               na.lp2 = samples$BUGSoutput$sims.list$NA.LP2,
               na.lp3 = samples$BUGSoutput$sims.list$NA.LP3)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='x']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('person country of origin')+ 
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='z']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('question country of origin')+ 
  guides(fill=FALSE)

c<-qplot(data=melt(df$alpha),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('alpha')+
  xlim(0,1)

d<-qplot(data=melt(df$beta),x=value,geom='histogram',binwidth=0.01)+
  theme_bw()+
  xlab('beta')+
  xlim(0,1)

e<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp1']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 1')+ 
  guides(fill=FALSE)

f<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp2']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 2')+ 
  guides(fill=FALSE)

g<- qplot(data=melt(df[,substr(names(df),1,6)=='na.lp3']),
  x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed',nrow=1)+
  xlab('NA LP 3')+ 
  guides(fill=FALSE)

#quartz('6.4.4')
grid.arrange(a,b,c,d,e,f,g,nrow=4)
```


# 6.5 Assessment of malingering

Armed with the knowledge from the previous sections, we now consider the practical challenge of detecting if people cheat on a test. For example, people who have been in a car accident may seek financial compensation from insurance companies by feigning cognitive impairment such as pronounced memory loss. When these people are confronted with a memory test that is intended to measure the extent of their impairment, they may deliberately under-perform. This behavior is called malingering, and it may be accompanied by performance much worse than that displayed by real amnesiacs. Sometimes, for example, malingerers may perform substantially below chance.

Malingering is not, however, always easy to detect, but is naturally addressed by latent-mixture modeling. Using this approach, it is possible to infer which of two categories—those who malinger, and those who are truthful or bona fide—each person belongs to, and quantify the confidence in each of these classifications.

```{r 6.5.1}
cat('# Malingering
model{
  # Each Person Belongs to One of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
    z1[i] <- z[i]+1
  }
  # Bona Fide Group has Unknown Success Rate Above Chance
  psi[1] ~ dunif(0.5,1)
  # Malingering Group has Unknown Success Rate Below Bona Fide
  psi[2] ~ dunif(0,psi[1])
  # Data are Binomial with Group Rate for Each Person
  for (i in 1:p){
    theta[i] <- psi[z1[i]]
    k[i] ~ dbin(theta[i],n)
  }
}
',file={f<-tempfile()})


k <- c(45,45,44,45,44,45,45,45,45,45,30,20,6,44,44,27,25,17,14,27,35,30)
p <- length(k) # number of people
n <- 45        # number of questions

data    <- list("p", "k", "n") # to be passed on to JAGS
myinits <- list(
  list(psi = c(0.7,0.5), z = round(runif(p)))) # Initial group assignment

# parameters to be monitored:  
parameters <- c("psi","z")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
               model.file=f, n.chains=1, n.iter=2000, 
               n.burnin=1000, n.thin=1, DIC=T)


df<-data.frame(psi = samples$BUGSoutput$sims.list$psi,
               z = samples$BUGSoutput$sims.list$z)

a<-qplot(data=melt(df[,substr(names(df),1,1)=='z']),
    x=factor(value),fill=factor(value),geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  xlab('bona fide or malingerer')+ 
  guides(fill=FALSE)

b<-qplot(data=melt(df[,substr(names(df),1,1)=='p']),
  x=value,fill=variable,geom='histogram',binwidth=0.02)+
  theme_bw()+
  facet_wrap(~variable,scales='fixed')+
  guides(fill=FALSE)+
  xlim(0,1)

grid.arrange(a,b)

```

Because this was an experimental study, we know that the first 10 participants were bona fide and the next 12 were instructed to malinger.

### Exercise 6.5.1 

What are your conclusions about group membership? Did all of the participants follow the instructions?

Seems that no. Participants 14 & 15 seemed to not follow the instructions.

# 6.6 Individual differences in malingering

As before, it may seem restrictive to assume that all members of a group have the same chance of answering correctly. So, now we assume that the ith participant in each group has a unique rate of answering questions correctly, θi, which is constrained by group-level distributions. In Section 6.2, we used group-level Gaussians. The problem with that approach is that values can lie outside the range 0 to 1. These values were just censored in Section 6.2, but this is not quite technically correct, and is certainly not elegant.

One of several alternatives is to assume that instead of being Gaussian, the group-level distribution is Beta(alpha,beta).

It is useful to transform the α and β parameters from the beta distribution to a group mean μ = α/(α+β) and a measure λ = α+β that can be conceived of as a precision, in the sense that as it increases the variability of the distribution decreases. It is then straightforward to assign uniform priors to both μb, the group- level mean for the bona fide participants, and μm, the group-level mean for the malingerers. This assignment does not, however, reflect our knowledge that μb > μm. To capture this knowledge, we could define dunif(0,mubon), as done in the previous model.

However, for this model we apply a different approach. We first define μm as the additive combination of μb and a difference parameter, so that logit(μm) = logit(μb) − μd. Note that this is an additive combination on the logit scale, as is customary in beta-binomial models. The logit transformation is defined as logit(θ) ≡ ln(θ/(1 − θ)) and it transforms values on the rate scale, ranging from 0 to 1, to values on the logit scale, ranging from −∞ to ∞.

```{r 6.6.1}
cat('# Malingering, with Individual Differences
model{
  # Each Person Belongs to One of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(phi) # phi is the Base Rate
    z1[i] <- z[i]+1
  }
  # Relatively Uninformative Prior on Base Rate
  phi ~ dbeta(5,5) 
  # Data are Binomial with Rate Given by 
  # Each Personís Group Assignment
  for (i in 1:p){
    k[i] ~ dbin(theta[i,z1[i]],n)
    theta[i,1] ~ dbeta(alpha[1],beta[1])
    theta[i,2] ~ dbeta(alpha[2],beta[2])
  }
  # Transformation to Group Mean and Precision
  alpha[1] <- mubon * lambdabon
  beta[1] <- lambdabon * (1-mubon)
  # Additivity on Logit Scale
  logit(mumal) <- logit(mubon) - mudiff
  alpha[2] <- mumal * lambdamal
  beta[2]  <- lambdamal * (1-mumal)
  # Priors
  mubon ~ dbeta(1,1) # uniform over coin weights
  mudiff ~ dnorm(0,0.5)T(0,) # Constrained to be Positive
  lambdabon ~ dunif(40,800) # higher precision for bonafide?
  lambdamal ~ dunif(4,100) # lower precision for malingerer?
}
',file={f<-tempfile()})

k <- c(45,45,44,45,44,45,45,45,45,45,30,20,6,44,44,27,25,17,14,27,35,30)
p <- length(k) # number of people
n <- 45        # number of questions

data <- list("p", "k", "n") # to be passed on to JAGS
myinits <- list(
  list(z = round(runif(p)), mudiff=0.2),
  list(z = round(runif(p)), mudiff=0.3),
  list(z = round(runif(p)), mudiff=0.4)) 

# parameters to be monitored:  
parameters <- c("theta","z","mubon","lambdabon",
               "mumal","lambdamal","mudiff","phi")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
               model.file = f, n.chains=3, n.iter=10000, 
               n.burnin=1000, n.thin=1, DIC=T)


df<-data.frame(theta = samples$BUGSoutput$sims.list$theta,
               z = samples$BUGSoutput$sims.list$z,
               mubon = samples$BUGSoutput$sims.list$mubon,
               lambdabon = samples$BUGSoutput$sims.list$lambdabon,
               mumal = samples$BUGSoutput$sims.list$mumal,
               lambdamal = samples$BUGSoutput$sims.list$lambdamal,
               mudiff = samples$BUGSoutput$sims.list$mudiff,
               phi = samples$BUGSoutput$sims.list$phi)

qplot(data=melt(df$phi),
  x=value,geom='histogram',binwidth=0.02)+
  theme_bw()+
  xlim(0,1)+
  xlab('phi (proportion of malingerers)')
```

### Exercise 6.6.1 

Is the inferred rate of malingering consistent with what is known
about the instructions given to participants?

Yes. It's about 0.5, and we know there were 10 bona fide and 12 malingerers in this data set. So yes, it's very consistent.

### Exercise 6.6.2 

Assume you know that the base rate of malingering is 10%. Change the WinBUGS script to reflect this knowledge. Do you expect any differences?

```{r 6.6.2}
cat('# Malingering, with Individual Differences
model{
  # Each Person Belongs to One of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(phi) # phi is the Base Rate
    z1[i] <- z[i]+1
  }
  # Base Rate set to 0.1
  phi <- 0.1
  # Data are Binomial with Rate Given by 
  # Each Personís Group Assignment
  for (i in 1:p){
    k[i] ~ dbin(theta[i,z1[i]],n)
    theta[i,1] ~ dbeta(alpha[1],beta[1])
    theta[i,2] ~ dbeta(alpha[2],beta[2])
  }
  # Transformation to Group Mean and Precision
  alpha[1] <- mubon * lambdabon
  beta[1] <- lambdabon * (1-mubon)
  # Additivity on Logit Scale
  logit(mumal) <- logit(mubon) - mudiff
  alpha[2] <- mumal * lambdamal
  beta[2]  <- lambdamal * (1-mumal)
  # Priors
  mubon ~ dbeta(1,1) # uniform over coin weights
  mudiff ~ dnorm(0,0.5)T(0,) # Constrained to be Positive
  lambdabon ~ dunif(40,800) # higher precision for bonafide?
  lambdamal ~ dunif(4,100) # lower precision for malingerer?
}
',file={f<-tempfile()})

k <- c(45,45,44,45,44,45,45,45,45,45,30,20,6,44,44,27,25,17,14,27,35,30)
p <- length(k) # number of people
n <- 45        # number of questions

data <- list("p", "k", "n") # to be passed on to JAGS
myinits <- list(
  list(z = round(runif(p)), mudiff=0.2),
  list(z = round(runif(p)), mudiff=0.3),
  list(z = round(runif(p)), mudiff=0.4)) 

# parameters to be monitored:  
parameters <- c("theta","z","mubon","lambdabon",
               "mumal","lambdamal","mudiff")

# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
               model.file = f, n.chains=3, n.iter=10000, 
               n.burnin=1000, n.thin=1, DIC=T)


df2<-data.frame(theta = samples$BUGSoutput$sims.list$theta,
               z = samples$BUGSoutput$sims.list$z,
               mubon = samples$BUGSoutput$sims.list$mubon,
               lambdabon = samples$BUGSoutput$sims.list$lambdabon,
               mumal = samples$BUGSoutput$sims.list$mumal,
               lambdamal = samples$BUGSoutput$sims.list$lambdamal,
               mudiff = samples$BUGSoutput$sims.list$mudiff)

a<-qplot(data=melt(df$mumal),
  x=value,geom='histogram',binwidth=0.02)+
  theme_bw()+
  xlim(0,1)+
  xlab('mu malingerers, unknown phi')

b<-qplot(data=melt(df2$mumal),
  x=value,geom='histogram',binwidth=0.02)+
  theme_bw()+
  xlim(0,1)+
  xlab('mu malingerers, phi = 0.1')

c<-qplot(data=melt(df$mubon),
  x=value,geom='histogram',binwidth=0.02)+
  theme_bw()+
  xlim(0,1)+
  xlab('mu bonafide, unknown phi')

d<-qplot(data=melt(df2$mubon),
  x=value,geom='histogram',binwidth=0.02)+
  theme_bw()+
  xlim(0,1)+
  xlab('mu bonafide, phi = 0.1')

grid.arrange(a,b,c,d,nrow=2)
```


# 6.7 Alzheimer's recall test cheating

Simple recognition and recall tasks are an important part of screening for Alzheimer’s Disease and Related Disorders (ADRD), and are sometimes administered over the telephone. This practice raises the possibility of people cheating by, for example, writing down the words they are being asked to remember.

By design, there are 61 bona fide people who are known to have done the task as intended, and 57 people who are known to have cheated.

```{r 6.7.1}

cat('# Cheating Latent Mixture Model
model{
  # Each Person Belongs to One of Two Latent Groups
  for (i in 1:p){
     z[i] ~ dbern(phi) # phi is the Base Rate
     z1[i] <- z[i]+1
  }
  # Relatively Uninformative Prior on Base Rate
  phi ~ dbeta(5,5) 
  # Data are Binomial with Rate Given by 
  # Each Personís Group Assignment
  for (i in 1:p){
    k[i] ~ dbin(theta[i,z1[i]],n)
    thetatmp[i,1] ~ dbeta(alpha[1],beta[1])
    theta[i,1] <- max(.01,min(.99,thetatmp[i,1]))
    thetatmp[i,2] ~ dbeta(alpha[2],beta[2])
    theta[i,2] <- max(.01,min(.99,thetatmp[i,2]))
  }
  # Transformation to Group Mean and Precision
  alpha[1] <- mubon * lambdabon
  beta[1] <- lambdabon * (1-mubon)
  # Additivity on Logit Scale
  logit(muche) <- logit(mubon) + mudiff # Note the "+"
  alpha[2] <- muche * lambdache
  beta[2] <- lambdache * (1-muche)
  # Priors
  mubon ~ dbeta(1,1)
  mudiff ~ dnorm(0,0.5)T(0,) # Constrained to be Positive
  lambdabon ~ dunif(5,50)
  lambdache ~ dunif(5,50)
  # Correct Count
  for (i in 1:p){
    pct[i] <- equals(z[i],truth[i])
  }
  pc <- sum(pct[1:p])
}',file={f<-tempfile()})

cheat.dat  <- read.table("cheat.csv",header=F,sep=",")
cheatt.dat <- read.table("cheatt.csv",header=F,sep="")
truth <- cheatt.dat$V1 #truth = 1 if cheater
k <- apply(cheat.dat,1,sum) # total correct per participant
p <- length(k) # number of people
n <- 40        # total trials

data <- list("p", "k", "n", "truth") # to be passed on to JAGS
myinits <- list(
  list(z = round(runif(p)), mudiff=0.1, phi=0.5, mubon=0.5, lambdabon=30, lambdache=25),
  list(z = round(runif(p)), mudiff=0.15, phi=0.5, mubon=0.5, lambdabon=25, lambdache=30)
  ) 

# parameters to be monitored:  
parameters <- c("theta","z","mubon","lambdabon",
               "muche","lambdache","mudiff","phi","alpha","beta","pc")

set.seed(3) # some chains result in "undefined real result -- see box & exercise"

samples = jags(data, inits=myinits, parameters,
               model.file =f, n.chains=2, n.iter=6000, 
               n.burnin=3000, n.thin=1, DIC=T)
               
pc <- samples$BUGSoutput$sims.list$pc/p #to get proportion correct
dfa<- rbind(data.frame(recalled=k[truth==0],group = 'bonafide'),
            data.frame(recalled=k[truth==1],group = 'cheat'))
  

qplot(data=dfa,x=recalled,geom='histogram',fill=group, binwidth=1,
      position='dodge')+
      theme_bw()

mean(pc)

# plot 6.9
#make the two panel plot:
windows(width=8,height=6) #this command works only under Windows!
layout(matrix(c(1,2),2,1))
layout.show(2)
par(cex.main = 1.5, mar = c(5, 6, 4, 5) + 0.1, 
    mgp = c(3.5, 1, 0), cex.lab = 1.5,
    font.lab = 2, cex.axis = 1.3, bty = "n", las=1)
bins <- c(-1:n)+.5
bonafide <- hist(k[truth==0], breaks=bins, plot=F)$counts
cheat    <- hist(k[truth==1], breaks=bins, plot=F)$counts

counts <- rbind(bonafide, cheat)
barplot(counts, main=" ", xlab=" ", col=c("grey","white"),
  legend.text = c("Bona Fide","Cheater"), args.legend = list(x="topleft"),
  beside=TRUE, axes=F)



# bottom panel:
par(cex.main = 1.5, mar = c(5, 6, 4, 5) + 0.1, mgp = c(3.5, 1, 0), cex.lab = 1.5,
    font.lab = 2, cex.axis = 1.3, bty = "n", las=1)
pc.line <- array()
for (i in 1:41)
{
  pc.line[i] <- mean((k>=(i-1))==truth)
}

dev.new() # so the plot below does not overwrite the plot above

plot(c(0:40), pc.line, type="l", lwd=2, xlim=c(0,40), ylim=c(0.4,1), 
     xlab="Number of Items Recalled Correctly", 
     ylab=" ", axes=F)
axis(1, at=c(0,seq(from=5,by=5,to=40)))
axis(2, at=c(.5,.75,1))
par(las=0)
mtext("Prop. Correct",side=2, line=2.5,cex=1.5)
# Now add the distribution:
pc.dens <- density(pc)
polygon(c(0,pc.dens$y,0,0), c(pc.dens$x[1]-.01,pc.dens$x,pc.dens$x[1]+.01,pc.dens$x[1]-.01), col="green")


# plot 6.10
par(cex.main = 1.5, mar = c(5, 6, 4, 5) + 0.1, mgp = c(3.5, 1, 0), cex.lab = 1.5,
    font.lab = 2, cex.axis = 1.3, bty = "n", las=1)
plot(k,samples$BUGSoutput$mean$z,ylim=c(0,1),xlim=c(0,n), xlab= "Number of Items Recalled Correctly", 
     ylab="Cheater Classification", lwd=2, pch=4) 
#in the code, z=0 is bonafide and z=1 is cheating
#so z gives the prob of being assigned to cheating group



```



