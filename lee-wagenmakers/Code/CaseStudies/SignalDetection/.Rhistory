geom_text(aes(x=n,y=1, label=round(correlation,2)),size=5,colour='black')+
scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.85))+
theme_bw()+
scale_x_continuous(breaks=3:11)+
scale_y_discrete()
total_objs = seq(3,11,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
model.all<-read.csv(paste(model.dir,d,'/00/csv/lis_N0_M0_tfbt',
d,'_qud1figFull_AIEOc4CAEP',EP,'_n',n_obj,
'_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- d
model.m<-melt(model.sub,
id.vars=c('X..syll','domain'))
model.domains<-rbind(model.domains, model.m)
}
#rename for merging
names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
n_obj = 4
corrs = c()
if (exists('models')){remove(models)}
# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj
total_objs = seq(3,9,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
dom.path = paste(model.dir,d,'/10/csv/',sep='')
model.files <- list.files(dom.path)
model.files <- model.files[!(grepl("CLonly",model.files))]
model.files <- model.files[!(grepl("1000k",model.files))]
model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
for (m.file in model.files){
model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- as.factor(d)
model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
model.domains<-rbind(model.domains, model.m)
}
}
#rename for merging
print(n_obj)
names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
# Load model predictions, for different parameter (n_object) values
# H4: n_objects, alpha (empirical prior + pragmatics)
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
n_obj = 4
corrs = c()
if (exists('models')){remove(models)}
# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj
total_objs = seq(3,9,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
dom.path = paste(model.dir,d,'/10/csv/',sep='')
model.files <- list.files(dom.path)
model.files <- model.files[!(grepl("CLonly",model.files))]
model.files <- model.files[!(grepl("1000k",model.files))]
model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
for (m.file in model.files){
model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- as.factor(d)
model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
model.domains<-rbind(model.domains, model.m)
}
}
#rename for merging
print(n_obj)
names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
models$syll <- factor(models$syll)
m.models<-melt(models, id.vars=c('syll','domain','alpha','conclusion'))
all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')],
by=c('syll','domain','conclusion'))
model.fits<-ddply(all.stuff, .(alpha, variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('alpha','n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
model.fits$alpha<-factor(model.fits$alpha)
max.loc<-which.max(model.fits$correlation)
ggplot(model.fits, aes(x=n,y=alpha))+
geom_tile(aes(fill = correlation), colour = "white") +
geom_tile(data=model.fits[max.loc,], aes(x=n,y=alpha, fill=correlation),
size=2,colour='black')+
geom_text(data=model.fits[max.loc,], aes(x=n,y=alpha, label=round(correlation,2)),
size=5,colour='black')+
scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.85))+
theme_bw()+
scale_x_continuous(breaks=3:11)
collapsed.bs <- subset(agr.ci.collapsed(melt(df.norm)),experiment==2)
collapsed.bs$conclusion = factor(collapsed.bs$variable, labels=c('all.C.A','none.C.A','some.C.A','not.all.C.A'))
collapsed.bs$domain = factor(collapsed.bs$domain, labels=domains)
# Load model predictions, for different parameter (n_object) values
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
syllogisms = c("AA1", "AI1", "EA1", "EI1")
if (exists('models')){remove(models)}
total_objs = seq(3,9,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
model.all<-read.csv(paste(model.dir,d,'/00/csv/lis_N0_M0_tfbt',
d,'_qud1figFull_AIEOc4CAEP',EP,'_n',n_obj,
'_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- d
model.m<-melt(model.sub,id.vars=c('X..syll','domain'))
model.domains<-rbind(model.domains, model.m)
}
#rename for merging
names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
models$syll <- factor(models$syll)
models$domain <- factor(models$domain)
cncl_labels = levels(models$conclusion)
m.models<-melt(models, id.vars=c('syll','domain','conclusion'))
all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')],
by=c('syll','domain','conclusion'))
model.fits<-ddply(all.stuff, .(variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
max.loc<-which.max(model.fits$correlation)
ggplot(model.fits, aes(x=n,y=factor(1)))+
geom_tile(aes(fill = correlation), colour = "white") +
geom_tile(data=model.fits[max.loc,], aes(x=n,y=1, fill=correlation),
size=2,colour='black')+
geom_text(aes(x=n,y=1, label=round(correlation,2)),size=5,colour='black')+
scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.8,0.95))+
theme_bw()+
scale_x_continuous(breaks=3:11)+
scale_y_discrete()
ggplot(subset(models), aes(x=conclusion,y=n7,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,0.7)
# Load model predictions, for different parameter (n_object) values
# H4: n_objects, alpha (empirical prior + pragmatics)
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c("AA1", "AI1", "EA1", "EI1")
if (exists('models')){remove(models)}
# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj
total_objs = seq(3,9,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
dom.path = paste(model.dir,d,'/10/csv/',sep='')
model.files <- list.files(dom.path)
model.files <- model.files[!(grepl("CLonly",model.files))]
model.files <- model.files[!(grepl("1000k",model.files))]
model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
for (m.file in model.files){
model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- as.factor(d)
model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
model.domains<-rbind(model.domains, model.m)
}
}
#rename for merging
print(n_obj)
names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
models$syll <- factor(models$syll)
m.models<-melt(models, id.vars=c('syll','domain','alpha','conclusion'))
all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')],
by=c('syll','domain','conclusion'))
model.fits<-ddply(all.stuff, .(alpha, variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('alpha','n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
model.fits$alpha<-factor(model.fits$alpha)
max.loc<-which.max(model.fits$correlation)
ggplot(model.fits, aes(x=n,y=alpha))+
geom_tile(aes(fill = correlation), colour = "white") +
geom_tile(data=model.fits[max.loc,], aes(x=n,y=alpha, fill=correlation),
size=2,colour='black')+
geom_text(data=model.fits[max.loc,], aes(x=n,y=alpha, label=round(correlation,2)),
size=5,colour='black')+
scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.99))+
theme_bw()+
scale_x_continuous(breaks=3:11)
ggplot(subset(models, alpha==2.5), aes(x=conclusion,y=n6,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,0.8)
ggplot(subset(models, alpha==2.5), aes(x=conclusion,y=n7,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,0.8)
ggplot(subset(models, alpha==2.5), aes(x=conclusion,y=n9,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,0.8)
# Load model predictions, for different parameter (n_object) values
# H4: n_objects, alpha (empirical prior + pragmatics)
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c("AA1", "AI1", "EA1", "EI1")
if (exists('models')){remove(models)}
# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj
total_objs = seq(3,9,2)
for (n_obj in total_objs){
model.domains = data.frame()
for (d in domains){
dom.path = paste(model.dir,d,'/10/csv/',sep='')
model.files <- list.files(dom.path)
model.files <- model.files[!(grepl("CLonly",model.files))]
model.files <- model.files[!(grepl("1000k",model.files))]
model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
for (m.file in model.files){
model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
model.sub<-model.all[model.all$X..syll%in%syllogisms,]
model.sub$domain <- as.factor(d)
model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
model.domains<-rbind(model.domains, model.m)
}
}
#rename for merging
print(n_obj)
names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
if (exists('models')){
models = merge(models,model.domains)
} else {
models = model.domains
}
}
models$syll <- factor(models$syll)
m.models<-melt(models, id.vars=c('syll','domain','alpha','conclusion'))
all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')],
by=c('syll','domain','conclusion'))
model.fits<-ddply(all.stuff, .(alpha, variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('alpha','n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
model.fits$alpha<-factor(model.fits$alpha)
max.loc<-which.max(model.fits$correlation)
ggplot(model.fits, aes(x=n,y=alpha))+
geom_tile(aes(fill = correlation), colour = "white") +
geom_tile(data=model.fits[max.loc,], aes(x=n,y=alpha, fill=correlation),
size=2,colour='black')+
geom_text(data=model.fits[max.loc,], aes(x=n,y=alpha, label=round(correlation,2)),
size=5,colour='black')+
scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.99))+
theme_bw()+
scale_x_continuous(breaks=3:11)
ggplot(subset(models, alpha==5.5), aes(x=conclusion,y=n7,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,0.8)
ggplot(subset(models, alpha==5.5), aes(x=conclusion,y=n7,fill=conclusion))+
geom_bar(stat='identity')+
facet_grid(domain~syll)+
theme_bw()+
ylim(0,1)
rm(list=ls())
setwd("~/Documents/learning/tfbt/Lee&Wagenmakers/Code/CaseStudies/SignalDetection")
source("heit_rotello.RData") #loads the data
library(reshape2)
library(ggplot2)
library(R2jags)
library(ggthemes)
cat('# Signal Detection Theory
model{
for (i in 1:k){
# Observed counts
h[i] ~ dbin(thetah[i],s[i])
f[i] ~ dbin(thetaf[i],n[i])
# Reparameterization Using Equal-Variance Gaussian SDT
thetah[i] <- phi(d[i]/2-c[i])
thetaf[i] <- phi(-d[i]/2-c[i])
# These Priors over Discriminability and Bias Correspond
# to Uniform Priors over the Hit and False Alarm Rates
d[i] ~ dnorm(0,0.5)
c[i] ~ dnorm(0,2)
}
}',file={fle<-tempfile()})
k <- 3 #number of cases
data <- matrix(c(70, 50, 30, 50, 7, 5, 3, 5, 10, 0, 0, 10), nrow=k, ncol=4, byrow=T)
h <- data[,1]
f <- data[,2]
MI <- data[,3]
CR <- data[,4]
s <- h + MI
n <- f + CR
data <- list("h", "f", "k", "s", "n") # to be passed on to JAGS
myinits <- list(
list(d = rep(0,k), c = rep(0,k)))
# parameters to be monitored:
parameters <- c("d", "c", "thetah", "thetaf")
# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
samples <- jags(data, inits=myinits, parameters,
model.file = fle, n.chains=1, n.iter=10000, n.burnin=1, n.thin=1)
df<- data.frame(d1 = samples$BUGSoutput$sims.list$d[,1],
d2 = samples$BUGSoutput$sims.list$d[,2],
d3 = samples$BUGSoutput$sims.list$d[,3],
c1 = samples$BUGSoutput$sims.list$c[,1],
c2 = samples$BUGSoutput$sims.list$c[,2],
c3 = samples$BUGSoutput$sims.list$c[,3],
h1 = samples$BUGSoutput$sims.list$thetah[,1],
h2 = samples$BUGSoutput$sims.list$thetah[,2],
h3 = samples$BUGSoutput$sims.list$thetah[,3],
f1 = samples$BUGSoutput$sims.list$thetaf[,1],
f2 = samples$BUGSoutput$sims.list$thetaf[,2],
f3 = samples$BUGSoutput$sims.list$thetaf[,3])
df.m<- melt(df)
df.m$metric <- factor(substring(df.m$variable,1,1),levels=c('d','c','h','f'),
labels=c('discriminability','bias','hit rate','false alarm rate'))
df.m$dset <- factor(substring(df.m$variable,2,2),labels=c('h=70/100, f=50/100',
'h=7/10, f=5/10',
'h=10/10 f=0/10'))
ggplot(df.m,aes(x=value,fill=dset))+
geom_density(alpha=0.5)+
facet_wrap(~metric,scale='free')+
theme_solarized()
library(gridExtra)
cat('# Hierarchical Signal Detection Theory
model{
for (i in 1:k){
# Observed counts
h[i] ~ dbin(thetah[i],s)
f[i] ~ dbin(thetaf[i],n)
# Reparameterization Using Equal-Variance Gaussian SDT
thetah[i] <- phi(d[i]/2-c[i])
thetaf[i] <- phi(-d[i]/2-c[i])
# Discriminability and Bias
c[i] ~ dnorm(muc,lambdac)
d[i] ~ dnorm(mud,lambdad)
}
# Priors
muc ~ dnorm(0,.001)
mud ~ dnorm(0,.001)
lambdac ~ dgamma(.001,.001)
lambdad ~ dgamma(.001,.001)
sigmac <- 1/sqrt(lambdac)
sigmad <- 1/sqrt(lambdad)
}',file={g<-tempfile()})
niter   <- 10000
nburnin <- 1000
for (dataset in 1:2) #analyze both conditions
{
if (dataset == 1)
data <- std_i # the induction data
if (dataset == 2)
data <- std_d # the deduction data
h <- data[,1]
f <- data[,2]
MI <- data[,3]
CR <- data[,4]
s <- h + MI
n <- f + CR
s <- s[1]; n <- n[1] #Each subject gets same number of signal and noise trials
k <- nrow(data)
data <- list("h", "f", "s", "n", "k") # to be passed on to JAGS
myinits <- list(
list(d = rep(0, k), c = rep(0, k), mud = 0, muc = 0, lambdad = 1, lambdac = 1))
# parameters to be monitored:
parameters <- c("mud", "muc", "sigmad", "sigmac")
if (dataset == 1) # induction
{
# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
isamples <- jags(data, inits=myinits, parameters,
model.file =g,
n.chains=1, n.iter=niter, n.burnin=nburnin, n.thin=1)
}
if (dataset == 2) # deduction
{
# The following command calls JAGS with specific options.
# For a detailed description see the R2jags documentation.
dsamples <- jags(data, inits=myinits, parameters,
model.file = g,
n.chains=1, n.iter=niter, n.burnin=nburnin, n.thin=1)
}
}
keepi <- 1000
keep <- sample(niter, keepi)
df <- data.frame(imud=isamples$BUGSoutput$sims.array[,,"mud"],
imuc=isamples$BUGSoutput$sims.array[,,"muc"],
dmud=dsamples$BUGSoutput$sims.array[,,"mud"],
dmuc=dsamples$BUGSoutput$sims.array[,,"muc"])
df.m<- melt(df)
df.m$task<- factor(substring(df.m$variable,1,1), levels=c("d","i"), labels=c("deduction","induction"))
df.m$param <- factor(substring(df.m$variable,4,4), levels=c("c","d"), labels=c("bias", "discriminability"))
df.m$seq <- with(df.m, ave(value, task, param, FUN = seq_along))
df.mc <- dcast(df.m, task + seq ~ param, value.var='value')
a<-ggplot(data=df.mc, aes(x=discriminability, y=bias, colour=task))+
geom_point()+
theme_solarized()+
xlim(-1,6)+
ylim(-3,3)
b<-ggplot(data=df.mc, aes(x=discriminability, fill=task))+
geom_density(alpha=0.5)+
theme_solarized()+
xlim(-1,6)
c<-ggplot(data=df.mc, aes(x=bias, fill=task))+
geom_density(alpha=0.5)+
theme_solarized()+
coord_flip()+
xlim(-3,3)
grid.arrange(a,c,b, nrow=2)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
head(df.mc)
head(df.mc,20)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
library(ddplyr)
install.packages("ddplyr")
na.mean <- function(x){mean(x,na.rm=na.rm)}
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
library(dplyr)
install.packages("dplyr")
library(dplyr)
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
na.mean <- function(x){mean(x,na.rm=na.rm)}
na.mean
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=TRUE)}
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
na.mean <- function(x){mean(x,na.rm=TRUE)}
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
library(bootstrap)
df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
df.summary <- df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,ci.high,ci.low),c(bias,discriminability))
df.summary
?quintile
?quantil
?quantile
df.summary <- df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,function(x){quantile(x,probs=c(0.025))},function(x){quantile(x,probs=c(0.975))},
c(bias,discriminability))
df.summary <- df.mc %>%
group_by(task) %>%
summarise_each(funs(na.mean,function(x){quantile(x,probs=c(0.025))},function(x){quantile(x,probs=c(0.975))},
c(bias,discriminability)))
quantile(subset(df.mc,task=='induction'),probs=c(0.025,0.975))
quantile(subset(df.mc,task=='induction')$discriminability,probs=c(0.025,0.975))
quantile(subset(df.mc,task=='deduction')$discriminability,probs=c(0.025,0.975))
quantile(subset(df.mc,task=='deduction')$discriminability-subset(df.mc,task=='induction')$discriminability,probs=c(0.025,0.975))
